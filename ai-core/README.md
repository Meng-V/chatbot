# AI-Core Backend

**Python FastAPI + LangGraph backend for Miami University Libraries Smart Chatbot**

This is the intelligent backend powering the chatbot with 6 specialized AI agents orchestrated by LangGraph.

---

## ğŸ¯ Key Features

- **Strict Scope Enforcement**: ONLY answers Miami University LIBRARIES questions (not general university)
- **Hybrid Router**: Automatically selects between fast function calling and complex multi-agent orchestration
- **7 Specialized Agents**: Primo, LibCal, LibGuide, Google Site, Subject Librarian, LibChat, Transcript RAG
- **Meta Router**: OpenAI o4-mini classifies user intent and detects out-of-scope questions
- **MuGuide Integration**: 710 subjects mapped to LibGuides and subject librarians
- **Contact Info Validation**: NEVER makes up emails, phone numbers, or names - only uses verified API data
- **Real-time Communication**: Socket.IO for WebSocket support
- **OAuth Integration**: Centralized token management for SpringShare APIs
- **Vector Search**: Weaviate integration for FAQ/documentation RAG
- **Production Ready**: Health monitoring, auto-restart, comprehensive logging

## ğŸš€ Quick Start

### Installation

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # macOS/Linux
# or .venv\Scripts\activate on Windows

# Install dependencies
pip install --upgrade pip
pip install -e .

# Generate Prisma client
prisma generate
```

### Configuration

The backend loads configuration from the **root `.env` file** (located at project root, not in ai-core directory).

```bash
# Navigate to project root
cd ..

# Copy template
cp .env.example .env

# Edit with your API keys
nano .env

# Optional: Create .env.local for local overrides (already in .gitignore)
cp .env.local.example .env.local
nano .env.local
```

**Environment File Structure:**
- `.env` - Main configuration file (contains all production values)
- `.env.local` - Local development overrides (not committed to git)
- `.env.example` - Template with placeholder values

See `DEVELOPER_GUIDE.md` for complete configuration instructions.

### Running

```bash
# Development (with auto-reload)
uvicorn src.main:app_sio --host 0.0.0.0 --port 8000 --reload

# Production
uvicorn src.main:app_sio --host 0.0.0.0 --port 8000
```

### Verification

```bash
# Health check
curl http://localhost:8000/health

# Test query
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"message":"What time does King Library close?"}'

# API documentation
open http://localhost:8000/docs
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test
pytest tests/test_all_agents.py -v
```

## ğŸ“¡ API Endpoints

- **GET /health** - System health and status
- **GET /readiness** - Readiness probe for orchestration
- **GET /metrics** - Performance metrics
- **POST /ask** - Main chat endpoint (HTTP JSON)
- **WebSocket** - `/smartchatbot/socket.io` - Real-time communication
- **GET /docs** - Interactive API documentation (Swagger UI)
- **GET /redoc** - Alternative API documentation

## ğŸ›ï¸ Architecture

```
Request Flow:
User Message
    â†“
Hybrid Router (complexity analysis)
    â†“
    â”œâ”€â†’ Simple: Function Calling (fast)
    â””â”€â†’ Complex: LangGraph Orchestration
            â†“
        Meta Router (intent classification)
            â†“
        Agent Selection (1-6 agents)
            â†“
        Parallel Execution
            â†“
        LLM Synthesis
            â†“
        Response to User
```

### Directory Structure

```
src/
â”œâ”€â”€ main.py              # FastAPI app, Socket.IO, CORS
â”œâ”€â”€ state.py             # LangGraph state definition
â”œâ”€â”€ agents/              # Specialized agents
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ primo_multi_tool_agent.py
â”‚   â”œâ”€â”€ libcal_comprehensive_agent.py
â”‚   â”œâ”€â”€ libguide_comprehensive_agent.py
â”‚   â”œâ”€â”€ google_site_comprehensive_agent.py
â”‚   â”œâ”€â”€ libchat_agent.py
â”‚   â””â”€â”€ transcript_rag_agent.py
â”œâ”€â”€ graph/               # LangGraph orchestration
â”‚   â”œâ”€â”€ orchestrator.py      # Main workflow
â”‚   â”œâ”€â”€ function_calling.py  # Fast mode
â”‚   â””â”€â”€ hybrid_router.py     # Smart routing
â”œâ”€â”€ tools/               # Agent tools
â”œâ”€â”€ services/            # OAuth services
â”œâ”€â”€ database/            # Prisma client
â”œâ”€â”€ memory/              # Conversation storage
â”œâ”€â”€ api/                 # Health/monitoring
â””â”€â”€ utils/               # Logging, helpers
```

## ğŸ¨ Customization

See `DEVELOPER_GUIDE.md` for detailed instructions on:
- Adding new agents
- Changing the LLM model
- Customizing response formatting
- Integrating new APIs

## ğŸ“š Documentation

- **User Guide**: See root `README.md`
- **Developer Guide**: See root `DEVELOPER_GUIDE.md`
- **API Docs**: http://localhost:8000/docs (when running)

## ğŸ”§ Troubleshooting

**Port in use:**
```bash
lsof -ti:8000 | xargs kill -9
```

**Import errors:**
```bash
pip install -e .
```

**Prisma not generated:**
```bash
prisma generate
```

**Database connection:**
```bash
# Verify DATABASE_URL in root .env
psql "postgresql://..."
```

---

**For complete documentation, see [DEVELOPER_GUIDE.md](../DEVELOPER_GUIDE.md)**
