#!/usr/bin/env python3
"""
é«˜çº§æ•°æ®è¿‡æ»¤ï¼šä½¿ç”¨AIè¾…åŠ©æ¸…æ´—ä½è´¨é‡å’Œä¸APIé‡å¤çš„Q&Aå¯¹
"""
import json
import os
import asyncio
from pathlib import Path
from typing import List, Dict, Any
from collections import defaultdict
import argparse
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# åŠ è½½ç¯å¢ƒå˜é‡
root_dir = Path(__file__).resolve().parent.parent.parent
load_dotenv(dotenv_path=root_dir / ".env")

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
# ä½¿ç”¨o4-miniæ¨¡å‹ï¼ˆä¸æ”¯æŒtemperatureå‚æ•°ï¼‰
llm = ChatOpenAI(model="o4-mini", api_key=OPENAI_API_KEY)

# ============================================================================
# è¿‡æ»¤è§„åˆ™å®šä¹‰
# ============================================================================

# ç®€å•å¯’æš„è¯­æ¨¡å¼ï¼ˆç›´æ¥è¿‡æ»¤ï¼Œä¸éœ€è¦AIï¼‰
SIMPLE_GREETINGS = [
    'hi', 'hello', 'hey', 'thanks', 'thank you', "you're welcome",
    'ok', 'okay', 'sure', 'yes', 'no', 'bye', 'goodbye',
    'got it', 'perfect', 'great', 'awesome', 'cool',
    'sorry', 'my bad', 'oops', 'alright', 'k', 'thx'
]

# API AgentèŒè´£å®šä¹‰ï¼ˆç”¨äºè¯†åˆ«é‡å¤ï¼‰
API_AGENT_CAPABILITIES = """
Miami University Libraries Chatbot ç°æœ‰API Agentsï¼š

1. **Primo Agent** - å®æ—¶å›¾ä¹¦é¦†ç›®å½•æ£€ç´¢
   - æœç´¢ä¹¦ç±ã€æ–‡ç« ã€æœŸåˆŠ
   - æ£€æŸ¥èµ„æºå¯ç”¨æ€§å’Œä½ç½®
   - è·å–call number
   - æŸ¥è¯¢ç”µå­èµ„æºè®¿é—®
   èŒè´£ï¼šä»»ä½•éœ€è¦æŸ¥è¯¢å½“å‰é¦†è—çš„é—®é¢˜

2. **LibCal Agent** - å®æ—¶å›¾ä¹¦é¦†æ—¶é—´å’Œç©ºé—´ç®¡ç†
   - æŸ¥è¯¢å›¾ä¹¦é¦†å¼€æ”¾æ—¶é—´ï¼ˆKing, Art & Architectureç­‰ï¼‰
   - é¢„è®¢å­¦ä¹ å®¤
   - æ£€æŸ¥æˆ¿é—´å¯ç”¨æ€§
   èŒè´£ï¼šä»»ä½•éœ€è¦å®æ—¶æ—¶é—´æˆ–é¢„è®¢ä¿¡æ¯çš„é—®é¢˜

3. **LibGuide Agent** - LibGuidesæ•°æ®åº“
   - è¯¾ç¨‹ç ”ç©¶æŒ‡å—
   - å­¦ç§‘æŒ‡å—
   - æ•°æ®åº“æ¨è
   èŒè´£ï¼šè¯¾ç¨‹ç›¸å…³çš„ç ”ç©¶æŒ‡å—æŸ¥è¯¢

4. **Subject Librarian Agent** - å­¦ç§‘é¦†å‘˜æ•°æ®åº“
   - æŸ¥æ‰¾ç‰¹å®šå­¦ç§‘çš„librarian
   - è·å–è”ç³»æ–¹å¼
   èŒè´£ï¼š"è°æ˜¯XXå­¦ç§‘çš„librarian"ç±»é—®é¢˜

5. **Google Site Agent** - å›¾ä¹¦é¦†ç½‘ç«™æœç´¢
   - æœç´¢lib.miamioh.eduå†…å®¹
   - æ”¿ç­–æ–‡æ¡£æŸ¥è¯¢
   èŒè´£ï¼šç½‘ç«™å†…å®¹æŸ¥è¯¢
"""

# AIè¿‡æ»¤æç¤ºè¯
FILTER_SYSTEM_PROMPT = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®è´¨é‡ä¸“å®¶ï¼Œè´Ÿè´£è¿‡æ»¤å›¾ä¹¦é¦†chatbotçš„RAGè®­ç»ƒæ•°æ®ã€‚

{API_AGENT_CAPABILITIES}

ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­æ¯ä¸ªQ&Aå¯¹æ˜¯å¦åº”è¯¥**åˆ é™¤**ã€‚éœ€è¦åˆ é™¤çš„æƒ…å†µï¼š

**1. ä½è´¨é‡å†…å®¹ï¼ˆå¿…åˆ ï¼‰**ï¼š
   - çº¯å¯’æš„è¯­ï¼ˆHi, Thanks, OKç­‰ï¼‰
   - æ— æ„ä¹‰çš„çŸ­è¯­ï¼ˆGot it, Sureç­‰ï¼‰
   - ä¸å®Œæ•´çš„å¥å­æˆ–é—®é¢˜
   - æ‹¼å†™ä¸¥é‡é”™è¯¯å¯¼è‡´æ— æ³•ç†è§£
   - æ”»å‡»æ€§ã€ä¸æ°å½“æˆ–éªšæ‰°æ€§å†…å®¹
   - ä¸ªäººä¿¡æ¯ï¼ˆç”µè¯å·ç ã€åœ°å€ç­‰ï¼Œä½†@miamioh.edué‚®ç®±å¯ä¿ç•™ï¼‰

**2. ä¸APIé‡å¤ï¼ˆå»ºè®®åˆ é™¤ï¼‰**ï¼š
   - **å®æ—¶æ•°æ®æŸ¥è¯¢**ï¼šé—®é¢˜éœ€è¦å®æ—¶æŸ¥è¯¢å½“å‰æ•°æ®ï¼ˆå¦‚"ä»Šå¤©å›¾ä¹¦é¦†å‡ ç‚¹å…³é—¨"ã€"è¿™æœ¬ä¹¦ç°åœ¨å¯å€Ÿå—"ï¼‰
   - **åŠ¨æ€ç›®å½•æ£€ç´¢**ï¼šéœ€è¦æœç´¢å½“å‰é¦†è—çš„é—®é¢˜ï¼ˆå¦‚"ä½ ä»¬æœ‰XXè¿™æœ¬ä¹¦å—"ï¼‰
   - **å®æ—¶é¢„è®¢**ï¼šéœ€è¦æ£€æŸ¥æˆ–é¢„è®¢æˆ¿é—´çš„é—®é¢˜
   - **å½“å‰æ—¶é—´è¡¨**ï¼šè¯¢é—®å½“å‰å­¦æœŸçš„å¼€æ”¾æ—¶é—´

**3. åº”è¯¥ä¿ç•™çš„ï¼ˆå³ä½¿çœ‹èµ·æ¥ä¸APIç›¸å…³ï¼‰**ï¼š
   - **æ“ä½œæŒ‡å—**ï¼šå¦‚ä½•ä½¿ç”¨æŸä¸ªæœåŠ¡ï¼ˆå¦‚"å¦‚ä½•ç»­å€Ÿä¹¦ç±"ã€"å¦‚ä½•ä½¿ç”¨ILL"ï¼‰
   - **æ”¿ç­–è§£é‡Š**ï¼šå›¾ä¹¦é¦†æ”¿ç­–è¯´æ˜ï¼ˆå¦‚"é€¾æœŸç½šæ¬¾æ˜¯å¤šå°‘"ã€"å¯ä»¥å€Ÿå‡ æœ¬ä¹¦"ï¼‰
   - **ä½¿ç”¨æŠ€å·§**ï¼šå¦‚ä½•æ“ä½œæ•°æ®åº“ã€å¦‚ä½•æ‰“å°ç­‰
   - **ä¸€èˆ¬æ€§çŸ¥è¯†**ï¼šä¸éœ€è¦å®æ—¶æ•°æ®çš„é—®é¢˜ï¼ˆå¦‚"ä»€ä¹ˆæ˜¯interlibrary loan"ï¼‰
   - **æ•…éšœæ’æŸ¥**ï¼šè§£å†³å¸¸è§é—®é¢˜çš„æ–¹æ³•
   - **å¤æ‚æ¡ˆä¾‹**ï¼šéœ€è¦librarianç»éªŒå’Œåˆ¤æ–­çš„é—®é¢˜

**åˆ¤æ–­åŸåˆ™**ï¼š
- å¦‚æœé—®é¢˜å¯ä»¥é€šè¿‡API**å®æ—¶æŸ¥è¯¢**æœ€æ–°æ•°æ®å›ç­” â†’ åˆ é™¤ï¼ˆè®©APIå¤„ç†ï¼‰
- å¦‚æœé—®é¢˜éœ€è¦**äººå·¥ç»éªŒ**ã€**è§£é‡Šè¯´æ˜**ã€**æ“ä½œæŒ‡å¯¼** â†’ ä¿ç•™ï¼ˆRAGä»·å€¼ï¼‰

è¯·å¯¹æ¯ä¸ªQ&Aå¯¹è¿”å›JSONæ ¼å¼ï¼š
{{
    "should_delete": true/false,
    "reason": "åˆ é™¤åŸå› åˆ†ç±»",
    "explanation": "ç®€çŸ­è§£é‡Šï¼ˆ1-2å¥è¯ï¼‰"
}}

åˆ é™¤åŸå› åˆ†ç±»åªèƒ½æ˜¯ä»¥ä¸‹ä¹‹ä¸€ï¼š
- "greeting": å¯’æš„è¯­
- "low_quality": ä½è´¨é‡å†…å®¹
- "inappropriate": ä¸æ°å½“å†…å®¹
- "api_duplicate": ä¸APIé‡å¤
- "keep": åº”è¯¥ä¿ç•™
"""


async def ai_judge_single_qa(qa: Dict[str, Any], batch_mode: bool = False) -> Dict[str, Any]:
    """
    ä½¿ç”¨AIåˆ¤æ–­å•ä¸ªQ&Aå¯¹æ˜¯å¦åº”è¯¥åˆ é™¤
    """
    question = qa.get('question', '')
    answer = qa.get('answer', '')
    topic = qa.get('topic', '')
    
    prompt = f"""
Q&Aå¯¹ä¿¡æ¯ï¼š
- ä¸»é¢˜åˆ†ç±»: {topic}
- é—®é¢˜: {question}
- ç­”æ¡ˆ: {answer[:200]}{"..." if len(answer) > 200 else ""}

è¯·åˆ¤æ–­è¿™ä¸ªQ&Aå¯¹æ˜¯å¦åº”è¯¥åˆ é™¤ï¼Œå¹¶è¿”å›JSONæ ¼å¼çš„åˆ¤æ–­ç»“æœã€‚
"""
    
    messages = [
        SystemMessage(content=FILTER_SYSTEM_PROMPT),
        HumanMessage(content=prompt)
    ]
    
    try:
        response = await llm.ainvoke(messages)
        result_text = response.content.strip()
        
        # è§£æJSON
        if result_text.startswith('```json'):
            result_text = result_text.split('```json')[1].split('```')[0].strip()
        elif result_text.startswith('```'):
            result_text = result_text.split('```')[1].split('```')[0].strip()
        
        result = json.loads(result_text)
        return result
    
    except Exception as e:
        print(f"âš ï¸  AIåˆ¤æ–­å‡ºé”™: {e}")
        # é»˜è®¤ä¿ç•™
        return {
            "should_delete": False,
            "reason": "keep",
            "explanation": "AIåˆ¤æ–­å‡ºé”™ï¼Œé»˜è®¤ä¿ç•™"
        }


def simple_filter(qa: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç®€å•è§„åˆ™è¿‡æ»¤ï¼ˆä¸éœ€è¦AIï¼‰
    """
    question = qa.get('question', '').lower().strip()
    answer = qa.get('answer', '').lower().strip()
    
    # 1. è¿‡æ»¤çº¯å¯’æš„è¯­
    if question in SIMPLE_GREETINGS or answer in SIMPLE_GREETINGS:
        return {
            "should_delete": True,
            "reason": "greeting",
            "explanation": "çº¯å¯’æš„è¯­"
        }
    
    # 2. é—®é¢˜æˆ–ç­”æ¡ˆå¤ªçŸ­ï¼ˆ<10å­—ç¬¦ï¼‰
    if len(question) < 10 or len(answer) < 10:
        return {
            "should_delete": True,
            "reason": "low_quality",
            "explanation": "å†…å®¹å¤ªçŸ­"
        }
    
    # 3. é—®é¢˜å’Œç­”æ¡ˆå®Œå…¨ç›¸åŒ
    if question == answer:
        return {
            "should_delete": True,
            "reason": "low_quality",
            "explanation": "é—®ç­”ç›¸åŒ"
        }
    
    # 4. åŒ…å«æ˜æ˜¾æ”»å‡»æ€§è¯æ±‡
    offensive_keywords = ['fuck', 'shit', 'damn', 'stupid', 'idiot', 'hate']
    if any(keyword in question or keyword in answer for keyword in offensive_keywords):
        return {
            "should_delete": True,
            "reason": "inappropriate",
            "explanation": "åŒ…å«ä¸å½“å†…å®¹"
        }
    
    # éœ€è¦AIè¿›ä¸€æ­¥åˆ¤æ–­
    return None


async def filter_qa_pairs_batch(
    qa_pairs: List[Dict[str, Any]], 
    use_ai: bool = True,
    batch_size: int = 10
) -> tuple[List[Dict[str, Any]], List[Dict[str, Any]], Dict[str, Any]]:
    """
    æ‰¹é‡è¿‡æ»¤Q&Aå¯¹
    
    Returns:
        (kept_pairs, deleted_pairs, filter_stats)
    """
    print(f"\nğŸ” å¼€å§‹é«˜çº§è¿‡æ»¤...")
    print(f"   åŸå§‹æ•°é‡: {len(qa_pairs)}")
    print(f"   ä½¿ç”¨AI: {use_ai}")
    
    kept_pairs = []
    deleted_pairs = []
    filter_stats = defaultdict(int)
    
    # ç¬¬1é˜¶æ®µï¼šç®€å•è§„åˆ™è¿‡æ»¤
    print(f"\nğŸ“‹ é˜¶æ®µ1: ç®€å•è§„åˆ™è¿‡æ»¤...")
    ai_review_queue = []
    
    for i, qa in enumerate(qa_pairs):
        simple_result = simple_filter(qa)
        
        if simple_result:
            if simple_result['should_delete']:
                filter_stats[simple_result['reason']] += 1
                # ä¿å­˜åˆ é™¤è®°å½•
                qa['_delete_reason'] = simple_result['explanation']
                qa['_delete_category'] = simple_result['reason']
                deleted_pairs.append(qa)
            else:
                kept_pairs.append(qa)
        else:
            # éœ€è¦AIåˆ¤æ–­
            ai_review_queue.append(qa)
        
        if (i + 1) % 1000 == 0:
            print(f"   è¿›åº¦: {i + 1}/{len(qa_pairs)}")
    
    print(f"   ç®€å•è§„åˆ™è¿‡æ»¤æ‰: {sum(filter_stats.values())}")
    print(f"   éœ€è¦AIå®¡æ ¸: {len(ai_review_queue)}")
    
    # ç¬¬2é˜¶æ®µï¼šAIå®¡æ ¸ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if use_ai and ai_review_queue:
        print(f"\nğŸ¤– é˜¶æ®µ2: AIæ™ºèƒ½è¿‡æ»¤...")
        print(f"   è¿™å°†è°ƒç”¨{len(ai_review_queue)}æ¬¡AI APIï¼Œå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
        
        # åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¿‡å¤šå¹¶å‘
        for batch_start in range(0, len(ai_review_queue), batch_size):
            batch_end = min(batch_start + batch_size, len(ai_review_queue))
            batch = ai_review_queue[batch_start:batch_end]
            
            # å¹¶å‘å¤„ç†batch
            tasks = [ai_judge_single_qa(qa) for qa in batch]
            results = await asyncio.gather(*tasks)
            
            for qa, result in zip(batch, results):
                if result['should_delete']:
                    filter_stats[result['reason']] += 1
                    # ä¿å­˜åˆ é™¤åŸå› åˆ°qaå¯¹è±¡
                    qa['_delete_reason'] = result['explanation']
                    qa['_delete_category'] = result['reason']
                    deleted_pairs.append(qa)
                else:
                    kept_pairs.append(qa)
            
            print(f"   AIè¿›åº¦: {batch_end}/{len(ai_review_queue)}")
    else:
        # ä¸ä½¿ç”¨AIï¼Œå…¨éƒ¨ä¿ç•™
        kept_pairs.extend(ai_review_queue)
    
    print(f"\nâœ… è¿‡æ»¤å®Œæˆ!")
    print(f"   ä¿ç•™: {len(kept_pairs)}")
    print(f"   åˆ é™¤: {len(deleted_pairs)}")
    
    return kept_pairs, deleted_pairs, dict(filter_stats)


async def main():
    parser = argparse.ArgumentParser(description='é«˜çº§æ•°æ®è¿‡æ»¤ï¼ˆAIè¾…åŠ©ï¼‰')
    parser.add_argument('input', help='è¾“å…¥JSONæ–‡ä»¶')
    parser.add_argument('--output', '-o', help='è¾“å‡ºJSONæ–‡ä»¶ï¼ˆé»˜è®¤: filtered_*.jsonï¼‰')
    parser.add_argument('--use-ai', action='store_true', default=True,
                        help='ä½¿ç”¨AIè¿›è¡Œæ™ºèƒ½è¿‡æ»¤ï¼ˆé»˜è®¤å¼€å¯ï¼‰')
    parser.add_argument('--no-ai', action='store_true',
                        help='åªä½¿ç”¨ç®€å•è§„åˆ™ï¼Œä¸è°ƒç”¨AI')
    parser.add_argument('--batch-size', type=int, default=10,
                        help='AIå¤„ç†æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤10ï¼‰')
    parser.add_argument('--sample', type=int,
                        help='åªå¤„ç†å‰Næ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if not args.output:
        input_path = Path(args.input)
        args.output = str(input_path.parent / f"filtered_{input_path.name}")
    
    print("ğŸš€ é«˜çº§æ•°æ®è¿‡æ»¤å¼€å§‹...")
    print(f"è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"è¾“å‡ºæ–‡ä»¶: {args.output}")
    
    # åŠ è½½æ•°æ®
    try:
        with open(args.input, 'r', encoding='utf-8') as f:
            qa_pairs = json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶: {e}")
        return
    
    print(f"âœ… åŠ è½½äº† {len(qa_pairs)} æ¡Q&Aå¯¹")
    
    # æµ‹è¯•æ¨¡å¼
    if args.sample:
        qa_pairs = qa_pairs[:args.sample]
        print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰ {args.sample} æ¡")
    
    # è¿‡æ»¤
    use_ai = args.use_ai and not args.no_ai
    filtered_pairs, deleted_pairs, stats = await filter_qa_pairs_batch(
        qa_pairs,
        use_ai=use_ai,
        batch_size=args.batch_size
    )
    
    # ä¿å­˜ä¿ç•™çš„æ•°æ®
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(filtered_pairs, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜è¢«åˆ é™¤çš„æ•°æ®ï¼ˆç”¨äºå®¡æŸ¥ï¼‰
    deleted_path = output_path.parent / f"deleted_{output_path.name}"
    with open(deleted_path, 'w', encoding='utf-8') as f:
        json.dump(deleted_pairs, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ—‘ï¸  è¢«åˆ é™¤çš„æ•°æ®å·²ä¿å­˜åˆ°: {deleted_path} (ç”¨äºå®¡æŸ¥)")
    
    print(f"\nâœ… è¿‡æ»¤åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
    print(f"ğŸ“¦ æœ€ç»ˆæ•°é‡: {len(filtered_pairs)} æ¡Q&Aå¯¹")
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "="*60)
    print("ğŸ“Š è¿‡æ»¤ç»Ÿè®¡")
    print("="*60)
    print(f"åŸå§‹æ•°é‡: {len(qa_pairs)}")
    print(f"ä¿ç•™æ•°é‡: {len(filtered_pairs)}")
    print(f"åˆ é™¤æ•°é‡: {len(qa_pairs) - len(filtered_pairs)}")
    
    if stats:
        print("\nåˆ é™¤åŸå› åˆ†å¸ƒ:")
        reason_names = {
            'greeting': 'å¯’æš„è¯­',
            'low_quality': 'ä½è´¨é‡',
            'inappropriate': 'ä¸å½“å†…å®¹',
            'api_duplicate': 'APIé‡å¤'
        }
        for reason, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
            reason_display = reason_names.get(reason, reason)
            print(f"  - {reason_display}: {count}")
    
    # ä¸»é¢˜åˆ†å¸ƒ
    print("\nä¿ç•™æ•°æ®çš„ä¸»é¢˜åˆ†å¸ƒ:")
    topic_counts = defaultdict(int)
    for qa in filtered_pairs:
        topic_counts[qa.get('topic', 'unknown')] += 1
    
    for topic, count in sorted(topic_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / len(filtered_pairs) * 100) if filtered_pairs else 0
        print(f"  - {topic}: {count} ({percentage:.1f}%)")
    
    print("\n" + "="*60)
    print("âœ¨ ä¸‹ä¸€æ­¥: python scripts/ingest_transcripts.py")
    print("="*60)


if __name__ == '__main__':
    asyncio.run(main())
