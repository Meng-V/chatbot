# å†å²å¯¹è¯æ•°æ®æ¸…ç†ä¸RAGä¼˜åŒ–ç­–ç•¥

## ğŸ“Š ç°çŠ¶åˆ†æ

### æ•°æ®è§„æ¨¡
- **æ€»é‡**ï¼š3å¹´ Ã— 2000æ¬¡/å¹´ = çº¦6000æ¡å¯¹è¯è®°å½•
- **æ–‡ä»¶å¤§å°**ï¼šå•ä¸ªCSVçº¦3MBï¼ˆçŸ­æœŸæ•°æ®ï¼‰ï¼Œå®Œæ•´æ•°æ®é¢„è®¡æ›´å¤§
- **å½“å‰RAGç»“æ„**ï¼šç®€å•çš„Q&Aå¯¹ï¼ˆquestion + answer + topic + sourceï¼‰

### CSVåŸå§‹æ•°æ®ç»“æ„
```
- Chat ID: å¯¹è¯å”¯ä¸€æ ‡è¯†
- Patron: ç”¨æˆ·ä¿¡æ¯
- Contact Info: è”ç³»æ–¹å¼
- Timestamp: æ—¶é—´æˆ³
- Wait Time / Duration: ç­‰å¾…å’Œå¯¹è¯æ—¶é•¿
- Rating (0-4): ç”¨æˆ·è¯„åˆ†
- Initial Question: åˆå§‹é—®é¢˜
- Transcript: å®Œæ•´å¯¹è¯è®°å½•ï¼ˆå¤šè½®å¯¹è¯ï¼Œæ—¶é—´æˆ³ + è¯´è¯äºº + å†…å®¹ï¼‰
- Tags: æ ‡ç­¾
- Message Count: æ¶ˆæ¯æ•°é‡
```

---

## ğŸ¯ æ•°æ®æ¸…ç†ç­–ç•¥

### 1ï¸âƒ£ **æ•°æ®è´¨é‡è¿‡æ»¤**

#### 1.1 æŒ‰è¯„åˆ†ç­›é€‰ï¼ˆä¼˜å…ˆçº§ï¼šé«˜ï¼‰
```python
# ä¿ç•™é«˜è´¨é‡å¯¹è¯
- Rating >= 3: é«˜è´¨é‡å›ç­”ï¼Œä¼˜å…ˆçº³å…¥RAG
- Rating == 2: éœ€äººå·¥å®¡æ ¸
- Rating <= 1 æˆ– Rating == 0ï¼ˆæ— è¯„åˆ†ï¼‰: è°¨æ…ä½¿ç”¨ï¼Œå¯èƒ½åŒ…å«é—®é¢˜
```

**å»ºè®®**ï¼š
- å…ˆç”¨Rating >= 3çš„æ•°æ®ï¼ˆçº¦60-70%ï¼‰æ„å»ºåŸºç¡€RAG
- æ— è¯„åˆ†çš„æ•°æ®å¯ä½œä¸ºè¡¥å……ï¼Œä½†éœ€é¢å¤–è´¨é‡æ£€æŸ¥

#### 1.2 æŒ‰å¯¹è¯é•¿åº¦ç­›é€‰
```python
# è¿‡æ»¤è¿‡çŸ­æˆ–è¿‡é•¿çš„å¯¹è¯
- Message Count < 2: æ— æ•ˆå¯¹è¯ï¼Œåˆ é™¤
- Message Count 2-20: æ­£å¸¸å¯¹è¯ï¼Œä¿ç•™
- Message Count > 20: è¶…é•¿å¯¹è¯ï¼Œéœ€æ‹†åˆ†å¤„ç†
```

#### 1.3 æŒ‰ä¸»é¢˜èŒƒå›´ç­›é€‰ï¼ˆæå…¶é‡è¦ï¼‰
æ ¹æ®ä½ çš„`scope_definition.py`ï¼Œå¿…é¡»ä¸¥æ ¼è¿‡æ»¤ï¼š

**ä¿ç•™**ï¼ˆIN_SCOPEï¼‰ï¼š
- å›¾ä¹¦é¦†èµ„æºæŸ¥è¯¢ï¼ˆä¹¦ç±ã€æ•°æ®åº“ã€æ–‡ç« ï¼‰
- å›¾ä¹¦é¦†æœåŠ¡ï¼ˆé¢„è®¢æˆ¿é—´ã€ç»­å€Ÿã€æ‰“å°ï¼‰
- å›¾ä¹¦é¦†ç©ºé—´å’Œå¼€æ”¾æ—¶é—´
- Subject Librarianå’¨è¯¢
- å›¾ä¹¦é¦†æ”¿ç­–ï¼ˆç½šæ¬¾ã€å€Ÿé˜…è§„åˆ™ï¼‰

**åˆ é™¤**ï¼ˆOUT_OF_SCOPEï¼‰ï¼š
- å¤§å­¦ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆå…¥å­¦ã€å­¦è´¹ã€ä½æˆ¿ï¼‰
- è¯¾ç¨‹ä½œä¸šå¸®åŠ©
- ITæŠ€æœ¯æ”¯æŒï¼ˆCanvasã€é‚®ç®±ï¼‰
- éå›¾ä¹¦é¦†è®¾æ–½

---

### 2ï¸âƒ£ **å¯¹è¯è§£æä¸åˆ†æ®µ**

#### 2.1 è§£æTranscriptå­—æ®µ
```python
# Transcriptæ ¼å¼ç¤ºä¾‹ï¼š
# "09:13:17 - Barry Zaslow : Hi Kayla..."
# "09:13:36 - Patron : Sadly I need..."

def parse_transcript(transcript_text):
    """
    å°†å®Œæ•´å¯¹è¯æ‹†åˆ†ä¸ºç»“æ„åŒ–çš„æ¶ˆæ¯åˆ—è¡¨
    """
    messages = []
    lines = transcript_text.split('\n')
    
    for line in lines:
        match = re.match(r'(\d{2}:\d{2}:\d{2}|\d{2}:\d{2}) - ([^:]+) : (.+)', line)
        if match:
            time, speaker, content = match.groups()
            messages.append({
                'time': time,
                'speaker': speaker.strip(),
                'content': content.strip()
            })
    
    return messages
```

#### 2.2 æå–Q&Aå¯¹ï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰

**ç­–ç•¥Aï¼šé¦–é—®-é¦–ç­”æå–**
```python
# æœ€ç®€å•ï¼Œé€‚åˆå¿«é€Ÿæ„å»º
def extract_first_qa(messages, initial_question):
    """
    æå–Initial Question + å›¾ä¹¦é¦†å‘˜çš„ç¬¬ä¸€ä¸ªå›ç­”
    """
    librarian_answer = None
    
    for msg in messages:
        if msg['speaker'] != 'Patron':  # å›¾ä¹¦é¦†å‘˜å›å¤
            librarian_answer = msg['content']
            break
    
    if librarian_answer:
        return {
            'question': initial_question,
            'answer': librarian_answer
        }
    return None
```

**ç­–ç•¥Bï¼šå¤šè½®å¯¹è¯æ‹†åˆ†ï¼ˆæ¨èï¼‰**
```python
# æ›´æ™ºèƒ½ï¼Œèƒ½æ•è·å®Œæ•´çš„äº¤äº’
def extract_all_qa_pairs(messages, initial_question):
    """
    å°†å¤šè½®å¯¹è¯æ‹†åˆ†ä¸ºå¤šä¸ªQ&Aå¯¹
    """
    qa_pairs = []
    current_question = initial_question
    current_answer_parts = []
    
    i = 0
    while i < len(messages):
        msg = messages[i]
        
        if msg['speaker'] == 'Patron':
            # å¦‚æœå·²æœ‰ç­”æ¡ˆï¼Œä¿å­˜å½“å‰Q&A
            if current_answer_parts:
                qa_pairs.append({
                    'question': current_question,
                    'answer': ' '.join(current_answer_parts)
                })
                current_answer_parts = []
            
            # æ›´æ–°é—®é¢˜
            current_question = msg['content']
        else:
            # å›¾ä¹¦é¦†å‘˜å›å¤
            current_answer_parts.append(msg['content'])
        
        i += 1
    
    # ä¿å­˜æœ€åä¸€å¯¹
    if current_answer_parts:
        qa_pairs.append({
            'question': current_question,
            'answer': ' '.join(current_answer_parts)
        })
    
    return qa_pairs
```

**ç­–ç•¥Cï¼šä¸Šä¸‹æ–‡çª—å£æ³•ï¼ˆæœ€æ™ºèƒ½ï¼‰**
```python
# ä¿ç•™å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œé€‚åˆå¤æ‚é—®é¢˜
def extract_qa_with_context(messages, initial_question, window_size=3):
    """
    æ¯ä¸ªQ&Aå¯¹åŒ…å«å‰åNæ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
    """
    qa_pairs = []
    
    for i, msg in enumerate(messages):
        if msg['speaker'] != 'Patron':  # å›¾ä¹¦é¦†å‘˜å›å¤
            # æ‰¾åˆ°å¯¹åº”çš„é—®é¢˜ï¼ˆå‘å‰æŸ¥æ‰¾æœ€è¿‘çš„patronæ¶ˆæ¯ï¼‰
            question = initial_question
            for j in range(i-1, -1, -1):
                if messages[j]['speaker'] == 'Patron':
                    question = messages[j]['content']
                    break
            
            # æå–ä¸Šä¸‹æ–‡çª—å£
            start = max(0, i - window_size)
            end = min(len(messages), i + window_size + 1)
            context = ' | '.join([
                f"{m['speaker']}: {m['content']}" 
                for m in messages[start:end]
            ])
            
            qa_pairs.append({
                'question': question,
                'answer': msg['content'],
                'context': context  # æ–°å¢å­—æ®µ
            })
    
    return qa_pairs
```

---

### 3ï¸âƒ£ **æ•°æ®å¢å¼ºä¸æ¸…ç†**

#### 3.1 æ¸…ç†å™ªéŸ³æ•°æ®
```python
def clean_message_content(text):
    """
    æ¸…ç†æ¶ˆæ¯ä¸­çš„å™ªéŸ³
    """
    # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<a href="[^"]*"[^>]*>([^<]*)</a>', r'\1', text)
    
    # ç§»é™¤é™„ä»¶é“¾æ¥
    text = re.sub(r'attached a file:.*?(?=\n|$)', '', text)
    
    # ç§»é™¤è¿‡çŸ­çš„å¯’æš„ï¼ˆå¯é€‰ï¼‰
    if len(text.strip()) < 10 and any(greeting in text.lower() for greeting in ['hi', 'hello', 'thanks', 'thank you', 'you\'re welcome']):
        return None
    
    # æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
    text = ' '.join(text.split())
    
    return text
```

#### 3.2 æå–ç»“æ„åŒ–ä¿¡æ¯
```python
def extract_metadata(chat_record):
    """
    æå–å…³é”®å…ƒæ•°æ®ç”¨äºåç»­è¿‡æ»¤å’Œåˆ†ç±»
    """
    metadata = {
        'chat_id': chat_record['Chat ID'],
        'timestamp': chat_record['Timestamp'],
        'rating': int(chat_record['Rating (0-4)']) if chat_record['Rating (0-4)'] else 0,
        'duration': int(chat_record['Duration (seconds)']),
        'message_count': int(chat_record['Message Count']),
        'tags': chat_record['Tags'].split(',') if chat_record['Tags'] else [],
        'department': chat_record['Department'],
        'answerer': chat_record['Answerer']
    }
    return metadata
```

#### 3.3 ä¸»é¢˜åˆ†ç±»ï¼ˆå…³é”®ï¼ï¼‰
```python
# åŸºäºä½ çš„scope_definition.pyè¿›è¡Œè‡ªåŠ¨åˆ†ç±»
TOPIC_KEYWORDS = {
    'discovery_search': ['book', 'article', 'journal', 'database', 'catalog', 'primo', 'find', 'search', 'call number'],
    'booking_or_hours': ['hours', 'open', 'close', 'room', 'reservation', 'book a room', 'study room'],
    'policy_or_service': ['renew', 'return', 'fine', 'overdue', 'print', 'scan', 'borrow', 'interlibrary loan', 'ILL'],
    'subject_librarian': ['librarian', 'subject specialist', 'research help', 'consultation', 'libguide'],
    'course_subject_help': ['course', 'class', 'ENG', 'PSY', 'CHM', 'guide for']
}

def classify_topic(question, answer):
    """
    æ ¹æ®å…³é”®è¯è‡ªåŠ¨åˆ†ç±»ä¸»é¢˜
    """
    combined_text = (question + ' ' + answer).lower()
    
    scores = {}
    for topic, keywords in TOPIC_KEYWORDS.items():
        score = sum(1 for kw in keywords if kw in combined_text)
        scores[topic] = score
    
    # è¿”å›å¾—åˆ†æœ€é«˜çš„ä¸»é¢˜ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å›'general'
    if max(scores.values()) > 0:
        return max(scores, key=scores.get)
    return 'general_question'
```

---

### 4ï¸âƒ£ **Weaviateæ•°æ®ç»“æ„ä¼˜åŒ–**

#### 4.1 å½“å‰ç»“æ„é—®é¢˜
```python
# ç°æœ‰schemaï¼ˆå¤ªç®€å•ï¼‰
{
    "question": str,
    "answer": str,
    "topic": str,
    "source": str
}
```

#### 4.2 ä¼˜åŒ–åçš„Schemaï¼ˆæ¨èï¼‰
```python
# å¢å¼ºç‰ˆschema
{
    # æ ¸å¿ƒå†…å®¹
    "question": str,              # ç”¨æˆ·é—®é¢˜
    "answer": str,                # å›¾ä¹¦é¦†å‘˜å›ç­”
    
    # åˆ†ç±»å’Œå…ƒæ•°æ®
    "topic": str,                 # ä¸»é¢˜åˆ†ç±»ï¼ˆdiscovery_search, booking_or_hoursç­‰ï¼‰
    "subtopic": str,              # å­ä¸»é¢˜ï¼ˆå¯é€‰ï¼Œæ›´ç»†ç²’åº¦åˆ†ç±»ï¼‰
    "keywords": [str],            # å…³é”®è¯åˆ—è¡¨
    
    # è´¨é‡æŒ‡æ ‡
    "rating": int,                # ç”¨æˆ·è¯„åˆ† 0-4
    "confidence_score": float,    # è´¨é‡ç½®ä¿¡åº¦ 0.0-1.0
    
    # ä¸Šä¸‹æ–‡ï¼ˆæ–°å¢ï¼ï¼‰
    "context": str,               # å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå‰åå‡ è½®å¯¹è¯ï¼‰
    "follow_up_questions": [str], # åç»­é—®é¢˜åˆ—è¡¨
    
    # å¯è¿½æº¯æ€§
    "source": str,                # æ¥æºæ ‡è¯†ï¼ˆtranscriptsï¼‰
    "chat_id": str,               # åŸå§‹Chat ID
    "timestamp": datetime,        # æ—¶é—´æˆ³
    "answerer": str,              # å›ç­”çš„å›¾ä¹¦é¦†å‘˜
    
    # å®ä½“æå–ï¼ˆé«˜çº§ï¼Œå¯é€‰ï¼‰
    "mentioned_resources": [str], # æåˆ°çš„èµ„æºï¼ˆä¹¦åã€æ•°æ®åº“åï¼‰
    "mentioned_urls": [str],      # æåˆ°çš„URL
    "mentioned_librarians": [str] # æåˆ°çš„å›¾ä¹¦é¦†å‘˜å§“å
}
```

#### 4.3 å‘é‡åŒ–ç­–ç•¥

**é€‰é¡¹Aï¼šå•ç‹¬å‘é‡åŒ–é—®é¢˜å’Œç­”æ¡ˆï¼ˆå½“å‰æ–¹æ¡ˆï¼‰**
```python
# åªç”¨questionç”Ÿæˆembedding
vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(
    vectorize_property_name='question'
)
```

**é€‰é¡¹Bï¼šç»„åˆå‘é‡åŒ–ï¼ˆæ¨èï¼‰**
```python
# ç»„åˆquestion + answer + contextç”Ÿæˆæ›´ä¸°å¯Œçš„embedding
def create_vectorization_text(qa_record):
    """
    åˆ›å»ºç”¨äºå‘é‡åŒ–çš„ç»„åˆæ–‡æœ¬
    """
    parts = [
        f"Question: {qa_record['question']}",
        f"Answer: {qa_record['answer']}"
    ]
    
    if qa_record.get('context'):
        parts.append(f"Context: {qa_record['context']}")
    
    if qa_record.get('keywords'):
        parts.append(f"Keywords: {', '.join(qa_record['keywords'])}")
    
    return ' | '.join(parts)
```

**é€‰é¡¹Cï¼šå¤šå‘é‡æ–¹æ¡ˆï¼ˆé«˜çº§ï¼‰**
```python
# ä¸ºquestionå’Œansweråˆ†åˆ«åˆ›å»ºå‘é‡ï¼Œæ”¯æŒæ›´ç²¾ç¡®çš„æ£€ç´¢
# éœ€è¦ä¿®æ”¹Weaviate schemaæ”¯æŒmultiple vectors
```

---

### 5ï¸âƒ£ **æ•°æ®åˆ†æ‰¹å¤„ç†æµç¨‹**

#### é˜¶æ®µ1ï¼šæ•°æ®æ¸…æ´—è„šæœ¬
```python
#!/usr/bin/env python3
"""
Step 1: æ¸…ç†åŸå§‹CSVæ•°æ®
è¾“å‡ºï¼šcleaned_transcripts.json
"""
import csv
import json
import re
from datetime import datetime

def clean_transcripts(csv_files):
    all_qa_pairs = []
    stats = {
        'total_chats': 0,
        'filtered_out': 0,
        'qa_pairs_extracted': 0
    }
    
    for csv_file in csv_files:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                stats['total_chats'] += 1
                
                # è´¨é‡è¿‡æ»¤
                if not should_include_chat(row):
                    stats['filtered_out'] += 1
                    continue
                
                # è§£æå¯¹è¯
                messages = parse_transcript(row['Transcript'])
                
                # æå–Q&Aå¯¹ï¼ˆä½¿ç”¨ç­–ç•¥Bæˆ–Cï¼‰
                qa_pairs = extract_all_qa_pairs(messages, row['Initial Question'])
                
                # æ·»åŠ å…ƒæ•°æ®å’Œæ¸…ç†
                for qa in qa_pairs:
                    # æ¸…ç†å†…å®¹
                    qa['question'] = clean_message_content(qa['question'])
                    qa['answer'] = clean_message_content(qa['answer'])
                    
                    if not qa['question'] or not qa['answer']:
                        continue
                    
                    # åˆ†ç±»ä¸»é¢˜
                    qa['topic'] = classify_topic(qa['question'], qa['answer'])
                    
                    # æ·»åŠ å…ƒæ•°æ®
                    qa['rating'] = int(row['Rating (0-4)']) if row['Rating (0-4)'] else 0
                    qa['source'] = 'transcripts'
                    qa['chat_id'] = row['Chat ID']
                    qa['timestamp'] = row['Timestamp']
                    qa['answerer'] = row['Answerer']
                    
                    # è´¨é‡è¯„åˆ†
                    qa['confidence_score'] = calculate_confidence_score(qa, row)
                    
                    all_qa_pairs.append(qa)
                    stats['qa_pairs_extracted'] += 1
    
    # ä¿å­˜ç»“æœ
    with open('cleaned_transcripts.json', 'w', encoding='utf-8') as f:
        json.dump(all_qa_pairs, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… å¤„ç†å®Œæˆï¼")
    print(f"   æ€»å¯¹è¯æ•°: {stats['total_chats']}")
    print(f"   è¿‡æ»¤æ‰: {stats['filtered_out']}")
    print(f"   æå–Q&Aå¯¹: {stats['qa_pairs_extracted']}")
    
    return all_qa_pairs

def should_include_chat(row):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥åŒ…å«è¿™æ¡å¯¹è¯
    """
    # è¿‡æ»¤ä½è´¨é‡
    rating = int(row['Rating (0-4)']) if row['Rating (0-4)'] else 0
    if rating == 1:
        return False
    
    # è¿‡æ»¤è¿‡çŸ­å¯¹è¯
    if int(row['Message Count']) < 2:
        return False
    
    # è¿‡æ»¤è¶…é•¿å¯¹è¯ï¼ˆå¯èƒ½æ˜¯å¤æ‚æ¡ˆä¾‹ï¼Œéœ€å•ç‹¬å¤„ç†ï¼‰
    if int(row['Message Count']) > 30:
        return False
    
    return True

def calculate_confidence_score(qa, row_metadata):
    """
    è®¡ç®—è´¨é‡ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰
    """
    score = 0.5  # åŸºç¡€åˆ†
    
    # è¯„åˆ†åŠ æƒ
    rating = qa.get('rating', 0)
    if rating >= 4:
        score += 0.3
    elif rating >= 3:
        score += 0.2
    elif rating >= 2:
        score += 0.1
    
    # ç­”æ¡ˆé•¿åº¦åŠ æƒï¼ˆä¸èƒ½å¤ªçŸ­ä¹Ÿä¸èƒ½å¤ªé•¿ï¼‰
    answer_len = len(qa['answer'])
    if 50 <= answer_len <= 500:
        score += 0.1
    elif 20 <= answer_len < 50 or 500 < answer_len <= 1000:
        score += 0.05
    
    # ç­”æ¡ˆä¸­åŒ…å«URLï¼ˆé€šå¸¸æ˜¯é«˜è´¨é‡å›ç­”ï¼‰
    if 'http' in qa['answer'] or 'www.' in qa['answer']:
        score += 0.1
    
    return min(1.0, score)
```

#### é˜¶æ®µ2ï¼šå»é‡å’Œåˆå¹¶
```python
"""
Step 2: å»é‡å’Œåˆå¹¶ç›¸ä¼¼é—®é¢˜
"""
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def deduplicate_qa_pairs(qa_pairs, similarity_threshold=0.85):
    """
    ä½¿ç”¨TF-IDFå’Œä½™å¼¦ç›¸ä¼¼åº¦å»é‡
    """
    if not qa_pairs:
        return []
    
    # æå–æ‰€æœ‰é—®é¢˜
    questions = [qa['question'] for qa in qa_pairs]
    
    # è®¡ç®—TF-IDFå‘é‡
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(questions)
    
    # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    similarity_matrix = cosine_similarity(tfidf_matrix)
    
    # æ ‡è®°é‡å¤é¡¹
    duplicates = set()
    merged_pairs = []
    
    for i in range(len(qa_pairs)):
        if i in duplicates:
            continue
        
        similar_indices = []
        for j in range(i + 1, len(qa_pairs)):
            if similarity_matrix[i][j] >= similarity_threshold:
                similar_indices.append(j)
                duplicates.add(j)
        
        # å¦‚æœæœ‰ç›¸ä¼¼é—®é¢˜ï¼Œåˆå¹¶ç­”æ¡ˆ
        if similar_indices:
            base_qa = qa_pairs[i].copy()
            similar_answers = [qa_pairs[j]['answer'] for j in similar_indices]
            
            # é€‰æ‹©æœ€é«˜è´¨é‡çš„ç­”æ¡ˆï¼ˆåŸºäºratingå’Œconfidence_scoreï¼‰
            all_candidates = [base_qa] + [qa_pairs[j] for j in similar_indices]
            best_qa = max(all_candidates, key=lambda x: (x['rating'], x['confidence_score']))
            
            merged_pairs.append(best_qa)
        else:
            merged_pairs.append(qa_pairs[i])
    
    print(f"âœ… å»é‡å®Œæˆ: {len(qa_pairs)} -> {len(merged_pairs)} (removed {len(duplicates)} duplicates)")
    
    return merged_pairs
```

#### é˜¶æ®µ3ï¼šæ‘„å…¥Weaviate
```python
"""
Step 3: æ‘„å…¥åˆ°Weaviate
ä¿®æ”¹ç°æœ‰çš„ ingest_transcripts.py
"""
def create_enhanced_schema(client):
    """
    åˆ›å»ºå¢å¼ºç‰ˆSchema
    """
    try:
        client.collections.create(
            name="TranscriptQA",
            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_openai(),
            properties=[
                # æ ¸å¿ƒå†…å®¹
                wvc.config.Property(name="question", data_type=wvc.config.DataType.TEXT),
                wvc.config.Property(name="answer", data_type=wvc.config.DataType.TEXT),
                
                # åˆ†ç±»
                wvc.config.Property(name="topic", data_type=wvc.config.DataType.TEXT),
                wvc.config.Property(name="keywords", data_type=wvc.config.DataType.TEXT_ARRAY),
                
                # è´¨é‡
                wvc.config.Property(name="rating", data_type=wvc.config.DataType.INT),
                wvc.config.Property(name="confidence_score", data_type=wvc.config.DataType.NUMBER),
                
                # ä¸Šä¸‹æ–‡ï¼ˆé‡è¦ï¼ï¼‰
                wvc.config.Property(name="context", data_type=wvc.config.DataType.TEXT),
                
                # å…ƒæ•°æ®
                wvc.config.Property(name="source", data_type=wvc.config.DataType.TEXT),
                wvc.config.Property(name="chat_id", data_type=wvc.config.DataType.TEXT),
                wvc.config.Property(name="timestamp", data_type=wvc.config.DataType.DATE),
                wvc.config.Property(name="answerer", data_type=wvc.config.DataType.TEXT),
            ]
        )
        print("âœ… Created enhanced TranscriptQA collection")
    except Exception as e:
        print(f"Schema creation error: {e}")

def ingest_with_batching(client, qa_pairs, batch_size=100):
    """
    åˆ†æ‰¹æ‘„å…¥æ•°æ®
    """
    collection = client.collections.get("TranscriptQA")
    
    total_batches = (len(qa_pairs) + batch_size - 1) // batch_size
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min((batch_num + 1) * batch_size, len(qa_pairs))
        batch = qa_pairs[start_idx:end_idx]
        
        with collection.batch.dynamic() as batch_inserter:
            for qa in batch:
                batch_inserter.add_object(
                    properties={
                        'question': qa['question'],
                        'answer': qa['answer'],
                        'topic': qa.get('topic', 'general'),
                        'keywords': qa.get('keywords', []),
                        'rating': qa.get('rating', 0),
                        'confidence_score': qa.get('confidence_score', 0.5),
                        'context': qa.get('context', ''),
                        'source': qa.get('source', 'transcripts'),
                        'chat_id': qa.get('chat_id', ''),
                        'timestamp': qa.get('timestamp', ''),
                        'answerer': qa.get('answerer', '')
                    }
                )
        
        print(f"âœ… Batch {batch_num + 1}/{total_batches} ingested ({end_idx}/{len(qa_pairs)} records)")
```

---

### 6ï¸âƒ£ **æŸ¥è¯¢ä¼˜åŒ–**

#### 6.1 ä¿®æ”¹transcript_rag_agent.py
```python
async def transcript_rag_query(query: str, log_callback=None, filters=None) -> Dict[str, Any]:
    """
    å¢å¼ºç‰ˆRAGæŸ¥è¯¢ï¼Œæ”¯æŒè¿‡æ»¤å’Œé‡æ’åº
    """
    def _search():
        if not client:
            return error_response()
        
        try:
            collection = client.collections.get("TranscriptQA")
            
            # æ„å»ºè¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼‰
            where_filter = None
            if filters:
                # ä¾‹å¦‚ï¼šåªæŸ¥è¯¢é«˜è¯„åˆ†çš„å›ç­”
                if filters.get('min_rating'):
                    where_filter = wvc.query.Filter.by_property('rating').greater_or_equal(filters['min_rating'])
                
                # æˆ–è€…æŒ‰ä¸»é¢˜è¿‡æ»¤
                if filters.get('topic'):
                    topic_filter = wvc.query.Filter.by_property('topic').equal(filters['topic'])
                    where_filter = where_filter & topic_filter if where_filter else topic_filter
            
            # æŸ¥è¯¢
            response = collection.query.near_text(
                query=query,
                limit=5,  # å¢åŠ åˆ°5ä¸ªç»“æœ
                where=where_filter,
                return_metadata=wvc.query.MetadataQuery(distance=True, score=True)
            )
            
            if not response.objects:
                return no_results_response()
            
            # é‡æ’åºï¼šæ ¹æ®confidence_scoreå’Œè·ç¦»ç»¼åˆè¯„åˆ†
            scored_results = []
            for obj in response.objects:
                props = obj.properties
                distance = obj.metadata.distance
                confidence = props.get('confidence_score', 0.5)
                
                # ç»¼åˆå¾—åˆ† = (1 - distance) * 0.7 + confidence * 0.3
                combined_score = (1 - distance) * 0.7 + confidence * 0.3
                
                scored_results.append({
                    'question': props.get('question', ''),
                    'answer': props.get('answer', ''),
                    'topic': props.get('topic', ''),
                    'rating': props.get('rating', 0),
                    'score': combined_score
                })
            
            # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
            scored_results.sort(key=lambda x: x['score'], reverse=True)
            
            # åªè¿”å›top 3
            top_results = scored_results[:3]
            
            # æ ¼å¼åŒ–è¾“å‡º
            answers = []
            for result in top_results:
                answers.append(f"**Q:** {result['question']}\n**A:** {result['answer']}")
            
            return {
                "source": "TranscriptRAG",
                "success": True,
                "text": "Based on similar questions from our knowledge base:\n\n" + "\n\n".join(answers),
                "confidence": "high" if top_results[0]['score'] > 0.8 else "medium",
                "matched_topic": top_results[0]['topic']
            }
        
        except Exception as e:
            return error_response(str(e))
    
    return await asyncio.to_thread(_search)
```

---

## ğŸ“ˆ å®æ–½å»ºè®®

### åˆ†é˜¶æ®µå®æ–½è®¡åˆ’

**Phase 1: å¿«é€ŸåŸå‹ï¼ˆ1-2å¤©ï¼‰**
1. ä½¿ç”¨ç­–ç•¥Aï¼ˆé¦–é—®-é¦–ç­”ï¼‰å¿«é€Ÿæå–
2. åªä½¿ç”¨Rating >= 3çš„æ•°æ®
3. åŸºæœ¬å»é‡
4. æ‘„å…¥500-1000æ¡æµ‹è¯•

**Phase 2: ä¼˜åŒ–è¿­ä»£ï¼ˆ3-5å¤©ï¼‰**
1. å®æ–½ç­–ç•¥Bï¼ˆå¤šè½®å¯¹è¯æ‹†åˆ†ï¼‰
2. æ·»åŠ ä¸»é¢˜åˆ†ç±»
3. å®æ–½TF-IDFå»é‡
4. å®Œæ•´æ‘„å…¥æ‰€æœ‰é«˜è´¨é‡æ•°æ®ï¼ˆçº¦3000-4000æ¡ï¼‰

**Phase 3: é«˜çº§ç‰¹æ€§ï¼ˆ1-2å‘¨ï¼‰**
1. å®æ–½ç­–ç•¥Cï¼ˆä¸Šä¸‹æ–‡çª—å£ï¼‰
2. å‡çº§Weaviate Schemaï¼ˆæ·»åŠ context, confidence_scoreç­‰ï¼‰
3. å®ä½“æå–ï¼ˆURLs, èµ„æºåç§°, å›¾ä¹¦é¦†å‘˜å§“åï¼‰
4. A/Bæµ‹è¯•ä¸åŒå‘é‡åŒ–ç­–ç•¥

### è´¨é‡ç›‘æ§

```python
# å®šæœŸè¯„ä¼°RAGè´¨é‡
def evaluate_rag_quality(test_queries):
    """
    ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢é›†è¯„ä¼°RAGæ•ˆæœ
    """
    metrics = {
        'avg_relevance': 0,
        'coverage': 0,
        'avg_confidence': 0
    }
    
    for query in test_queries:
        result = transcript_rag_query(query)
        # è®¡ç®—ç›¸å…³æ€§ã€è¦†ç›–ç‡ç­‰æŒ‡æ ‡
        # ...
    
    return metrics
```

---

## ğŸš€ é¢„æœŸæ•ˆæœ

### ä¼˜åŒ–å‰ï¼ˆå½“å‰çŠ¶æ€ï¼‰
- ç®€å•Q&Aå¯¹
- æ— è´¨é‡æ§åˆ¶
- æ— ä¸»é¢˜åˆ†ç±»
- æŸ¥è¯¢ç»“æœè´¨é‡ä¸ç¨³å®š

### ä¼˜åŒ–å
- **æ•°æ®è´¨é‡**ï¼šåªåŒ…å«é«˜è¯„åˆ†ï¼ˆ3+ï¼‰å¯¹è¯
- **è¦†ç›–èŒƒå›´**ï¼šä»6000æ¡å¯¹è¯ä¸­æå–çº¦5000-8000ä¸ªé«˜è´¨é‡Q&Aå¯¹
- **æ£€ç´¢ç²¾åº¦**ï¼šé€šè¿‡ä¸»é¢˜è¿‡æ»¤å’Œé‡æ’åºæå‡ç›¸å…³æ€§
- **ä¸Šä¸‹æ–‡ç†è§£**ï¼šä¿ç•™å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ç†è§£
- **å¯è¿½æº¯æ€§**ï¼šæ¯æ¡å›ç­”å¯è¿½æº¯åˆ°åŸå§‹å¯¹è¯è®°å½•

### é€‚ç”¨åœºæ™¯åˆ†å¸ƒ
- **ç›´æ¥å›ç­”**ï¼šçº¦60-70%çš„å¸¸è§é—®é¢˜å¯ç›´æ¥ä»RAGå›ç­”
- **è¾…åŠ©å›ç­”**ï¼šçº¦20-30%éœ€è¦ç»“åˆAPIå’ŒRAG
- **è½¬äººå·¥**ï¼šçº¦10%å¤æ‚é—®é¢˜éœ€è¦äººå·¥ä»‹å…¥

---

## ğŸ› ï¸ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¼€å§‹**ï¼šè¿è¡Œæ•°æ®æ¸…æ´—è„šæœ¬ï¼ˆPhase 1ï¼‰
2. **é€æ­¥ä¼˜åŒ–**ï¼šåŸºäºå®é™…æŸ¥è¯¢æ•ˆæœè¿­ä»£æ”¹è¿›
3. **æŒç»­æ›´æ–°**ï¼šæ¯å­£åº¦è¡¥å……æ–°çš„å¯¹è¯æ•°æ®
4. **ç›‘æ§æŒ‡æ ‡**ï¼šè·Ÿè¸ªRAGå‘½ä¸­ç‡ã€ç”¨æˆ·æ»¡æ„åº¦

æ˜¯å¦éœ€è¦æˆ‘å¼€å§‹å®ç°å…·ä½“çš„æ¸…æ´—è„šæœ¬ï¼Ÿ
